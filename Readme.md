# PDF Heading Extractor (Challenge 1A)

A containerized Python-based tool that semantically extracts and detects hierarchical headings (H1, H2, H3) from PDF documents with multilingual support.

--

## Features

- **Semantic Heading Detection**: Automatically identifies meaningful headings (H1, H2, H3) using contextual cues.
- **Multilingual Support**: Utilizes `sentence-transformers` to understand and process PDFs in multiple languages.
- **Dockerized**: Easily run in a containerized environment with no dependency conflicts.
- **Folder-Based Input/Output**: Reads from a given input folder and writes the processed output to a designated output directory.
- **Modular Design**: Easily extendable to include new models or formats (e.g., FastText support coming soon).

--

## ğŸ“š Theoretical Overview

To identify headings (H1, H2, H3) from PDF documents, we apply a combination of heuristic rules and semantic models:

### ğŸ§  Semantic Understanding
We leverage [Sentence Transformers](https://www.sbert.net/) to compute contextual sentence embeddings. These allow us to compare textual content semantically, ensuring multilingual support and meaning-based grouping of headings.

### ğŸ› ï¸ Heuristic Features
Each line of text is scored using the following heuristic features:

| Heuristic Feature         | Role in Detection                                              |
|--------------------------|----------------------------------------------------------------|
| **Font Size**             | Larger font often implies higher heading level (e.g., H1).     |
| **Font Weight**           | Bold fonts are favored as headings.                            |
| **Font Color**            | Consistent or distinct color is used as a visual cue for headings. |
| **Center Alignment**      | Centered text receives a boost in heading score.               |
| **Text Length**           | Very long lines are penalized (not likely headings).           |
| **List/Bullet Detection** | Filters out numbered/bulleted content (`1.`, `â€¢`, `a)`, etc.). |

The combination of these rules and semantic embeddings allows for a more accurate classification of document structure, even across languages and diverse formatting styles.
```

--

## Project Structure

```

CHALLENGE\_1A/
â”œâ”€â”€ sample-dataset/
â”‚   â”œâ”€â”€ pdfs/               # Place input PDFs here
â”‚   â”œâ”€â”€ output/             # Output results saved here
â”‚   â””â”€â”€ schema/             # Optional schema definitions
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ process\_pdfs.py         # Core logic for PDF heading extraction
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

--

## Setup & Usage

### Option 1: Run Using Docker (Recommended)

#### Step 1: Pull the Docker Image from Docker Hub

```bash
docker pull dhanush489/adobehackathon1a:1a
````

#### Step 2: Create Input and Output Folders

```
your-folder/
â”œâ”€â”€ input/         # Place PDFs to be processed here
â””â”€â”€ output/        # Processed results will appear here
```

#### Step 3: Run the Container

```bash
docker run --rm \
    -v "$(pwd)/input:/app/sample-dataset/pdfs:ro" \
    -v "$(pwd)/output:/app/sample-dataset/output" \
    --network none \
    dhanush489/adobehackathon1a:1a
```

### Option 2: ğŸ§ª Run Locally via Python

#### Step 1: Clone the Repository

```bash
git clone https://github.com/your-username/pdf-heading-extractor.git
cd pdf-heading-extractor
```

#### Step 2: Install Dependencies

```bash
pip install -r requirements.txt
```

#### Step 3: Process PDFs

Make sure your input PDFs are in `sample-dataset/pdfs`, then run:

```bash
python process_pdfs.py
```

Output will be saved in `sample-dataset/output`.

--

## ğŸ”® Future Enhancements

* âœ… Integrate [FastText](https://fasttext.cc/) for lightweight language detection.
* ğŸ” Add OCR support for scanned PDFs to improve layout analysis.
* ğŸ“Š Export heading data in structured formats (JSON, CSV, XML).
* ğŸ“ˆ GUI or web interface for easier usage.


